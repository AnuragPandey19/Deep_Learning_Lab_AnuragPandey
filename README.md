# ğŸ§  Deep Learning Experiments

<div align="center">

![Deep Learning](https://img.shields.io/badge/Deep%20Learning-Experiments-blue?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.8+-green?style=for-the-badge&logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)

**A comprehensive collection of deep learning experiments from fundamentals to advanced applications**

[View Experiments](#-experiments) â€¢ [Setup](#ï¸-setup--installation) â€¢ [Technologies](#-technologies-used)

</div>

---

## ğŸ“‹ Table of Contents

- [About](#-about)
- [Repository Structure](#-repository-structure)
- [Experiments](#-experiments)
- [Setup & Installation](#ï¸-setup--installation)
- [Technologies Used](#-technologies-used)

---

## ğŸ¯ About

This repository contains hands-on implementations of deep learning concepts, covering everything from basic neural network components to advanced transfer learning techniques. Each experiment is designed to build practical understanding through implementation and analysis.

---

## ğŸ“ Repository Structure

```
ğŸ“¦ Deep-Learning-Experiments
â”£ ğŸ“‚ Exp_1
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”£ ğŸ“‚ Exp_2
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”£ ğŸ“‚ Exp_3
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”£ ğŸ“‚ Exp_4
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”£ ğŸ“‚ Exp_5
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”£ ğŸ“‚ Exp_6
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”£ ğŸ“‚ Exp_7
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”£ ğŸ“‚ Exp_8
â”ƒ â”£ ğŸ““ experiment.ipynb
â”ƒ â”£ ğŸ“‚ datasets
â”ƒ â”— ğŸ“‚ images
â”— ğŸ“„ README.md
```

> Each experiment folder is self-contained with its notebook, datasets, and generated visualizations.

---

## ğŸ”¬ Experiments

<table>
<tr>
<td width="50%">

### ğŸ“Š Experiment 1
**Comparative Study of Deep Learning Frameworks**

```
Topics:
â”œâ”€â”€ TensorFlow Implementation
â”œâ”€â”€ Keras Implementation
â”œâ”€â”€ PyTorch Implementation
â””â”€â”€ Framework Comparison
```

Compare TensorFlow, Keras, and PyTorch by implementing linear regression. Analyze code verbosity, API design patterns, and debugging capabilities across frameworks.

</td>
<td width="50%">

### ğŸ”§ Experiment 2
**Neural Networks from Scratch**

```
Topics:
â”œâ”€â”€ Single Neuron (AND Gate)
â”œâ”€â”€ Feedforward Network (XOR)
â”œâ”€â”€ MLP with Backpropagation
â””â”€â”€ Activation & Loss Functions
```

Build neural network components from ground up without high-level libraries. Implement forward propagation, backpropagation, and training mechanisms.

</td>
</tr>

<tr>
<td width="50%">

### ğŸ¯ Experiment 3
**Classification with DL Frameworks**

```
Topics:
â”œâ”€â”€ Dataset: MNIST/Fashion-MNIST
â”œâ”€â”€ Data Preprocessing
â”œâ”€â”€ Model Training & Validation
â””â”€â”€ Performance Evaluation
```

End-to-end classification pipeline using deep learning frameworks. Includes data normalization, model building, training curves, and confusion matrix analysis.

</td>
<td width="50%">

### ğŸ–¼ï¸ Experiment 4
**Transfer Learning for Image Classification**

```
Topics:
â”œâ”€â”€ Pretrained Models
â”œâ”€â”€ Feature Extraction
â”œâ”€â”€ Fine-Tuning Strategies
â””â”€â”€ Cats vs Dogs / CIFAR-10
```

Leverage pretrained models (ResNet, EfficientNet, MobileNet) for image classification. Implement both feature extraction and fine-tuning approaches.

</td>
</tr>

<tr>
<td width="50%">

### âš¡ Experiment 5
**Training Deep Networks**

```
Topics:
â”œâ”€â”€ Activation Functions Visualization
â”œâ”€â”€ Loss Functions Implementation
â”œâ”€â”€ Backpropagation Algorithm
â””â”€â”€ Optimizer Comparison
```

Deep dive into training mechanisms. Visualize activation functions (Sigmoid, ReLU, Tanh, Softmax) and loss functions. Compare SGD, Momentum, and Adam optimizers.

</td>
<td width="50%">

### ğŸ”· Experiment 6
**Multi-Layer Perceptron**

```
Topics:
â”œâ”€â”€ MLP Architecture Design
â”œâ”€â”€ Layer Configuration
â”œâ”€â”€ Hyperparameter Tuning
â””â”€â”€ Classification Tasks
```

Build and train MLP architectures with various configurations. Explore different layer depths, neuron counts, and activation strategies.

</td>
</tr>

<tr>
<td colspan="2">

### ğŸ–¥ï¸ Experiment 7
**Convolutional Neural Networks**

```
Topics:
â”œâ”€â”€ Convolution Operations          â”œâ”€â”€ Pooling Layers (Max, Average)
â”œâ”€â”€ Feature Map Extraction          â””â”€â”€ CNN Architecture Design
```

Implement CNN components from scratch. Visualize learned features through feature maps and understand how convolution and pooling operations work.

</td>
</tr>

<tr>
<td colspan="2">

### ğŸ¨ Experiment 8
**CNN with Data Augmentation for Image Classification**

```
Topics:
â”œâ”€â”€ Data Augmentation Techniques    â”œâ”€â”€ Image Transformations (Rotation, Flip, Zoom)
â”œâ”€â”€ CNN Model Training              â””â”€â”€ Performance Comparison with/without Augmentation
```

Implement CNN with data augmentation strategies to improve model generalization. Apply various image transformations and analyze their impact on classification accuracy.

</td>
</tr>
</table>

---

## ğŸ› ï¸ Setup & Installation

### Prerequisites

```bash
Python 3.8+
Jupyter Notebook
GPU (Optional, for faster training)
```

### Installation Steps

```bash
# 1. Clone the repository
git clone <repository-url>
cd deep-learning-experiments

# 2. Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install tensorflow keras torch torchvision numpy pandas matplotlib seaborn scikit-learn jupyter

# 4. Launch Jupyter Notebook
jupyter notebook
```

### Running an Experiment

```bash
# Navigate to experiment folder
cd Exp_1

# Open the notebook
jupyter notebook experiment.ipynb

# Or use JupyterLab
jupyter lab experiment.ipynb
```

---

## ğŸ”§ Technologies Used

<div align="center">

| Framework | Version | Purpose |
|-----------|---------|---------|
| ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-FF6F00?logo=tensorflow) | 2.x | Deep Learning Framework |
| ![Keras](https://img.shields.io/badge/Keras-2.x-D00000?logo=keras) | 2.x | High-level Neural Networks API |
| ![PyTorch](https://img.shields.io/badge/PyTorch-2.x-EE4C2C?logo=pytorch) | 2.x | Deep Learning Framework |
| ![NumPy](https://img.shields.io/badge/NumPy-1.x-013243?logo=numpy) | 1.x | Numerical Computing |
| ![Pandas](https://img.shields.io/badge/Pandas-2.x-150458?logo=pandas) | 2.x | Data Manipulation |
| ![Matplotlib](https://img.shields.io/badge/Matplotlib-3.x-11557c?logo=python) | 3.x | Data Visualization |
| ![Scikit Learn](https://img.shields.io/badge/Scikit_Learn-1.x-F7931E?logo=scikit-learn) | 1.x | Machine Learning Tools |

</div>

---

<div align="center">

### ğŸŒŸ Star this repository if you find it helpful!

**Anurag Pandey**

</div>
